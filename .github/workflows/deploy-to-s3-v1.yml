name: Deploy to S3

on:
  # push:
  #   branches:
  #     - main
  #     - dev
  #     - stg
  #   paths:
  #     - 'CFN/**'
  #     - 'Lambdas/**'
  #     - '.github/workflows/deploy-to-s3.yml'

  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - stg
          - prod
      deploy_cfn:
        description: 'Deploy CloudFormation templates'
        required: true
        default: true
        type: boolean
      deploy_lambdas:
        description: 'Deploy Lambda functions'
        required: true
        default: true
        type: boolean
  
# Cancel in-progress runs when a new run starts for the same ref
# This prevents queue buildup and saves runner time
concurrency:
  # Group runs by workflow name and git ref (branch/tag/PR)
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

# Global environment variables available to all jobs
env:
  # AWS Configuration
  AWS_REGION: us-east-1
  
  # S3 Bucket configuration - using different buckets per environment
  # These can be overridden in job-level env or using secrets
  S3_BUCKET_DEV: dev-cyngular-onboarding
  S3_BUCKET_STAGING: stg-cyngular-onboarding  
  S3_BUCKET_PROD: cyngular-onboarding
  
  # Python version for consistency
  PYTHON_VERSION: '3.11'

# Permissions needed for AWS OIDC authentication
# This is more secure than storing AWS credentials as secrets
permissions:
  # Required for requesting the OIDC JWT token
  id-token: write
  # Required for actions/checkout to fetch code
  contents: read
  # Required for uploading artifacts (optional)
  actions: read

jobs:
  # Job 1: Validate and prepare deployment configuration
  prepare-deployment:
    name: Prepare Deployment Configuration
    runs-on: ubuntu-latest
    
    # Output values that other jobs can reference
    outputs:
      s3_bucket: ${{ steps.set-bucket.outputs.bucket }}
      environment: ${{ steps.set-env.outputs.environment }}
      timestamp: ${{ steps.set-timestamp.outputs.timestamp }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          # Fetch full history for better git information
          fetch-depth: 0
      
      # Determine environment from trigger context
      - name: Determine environment
        id: set-env
        run: |
          # If manual trigger, use the input value
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            echo "environment=${{ github.event.inputs.environment }}" >> $GITHUB_OUTPUT
          # Otherwise, map branch to environment
          elif [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "environment=prod" >> $GITHUB_OUTPUT
          elif [[ "${{ github.ref }}" == "refs/heads/stg" ]]; then
            echo "environment=stg" >> $GITHUB_OUTPUT
          else
            echo "environment=dev" >> $GITHUB_OUTPUT
          fi
      
      # Select S3 bucket based on environment
      - name: Set S3 bucket
        id: set-bucket
        run: |
          ENV="${{ steps.set-env.outputs.environment }}"
          if [[ "$ENV" == "prod" ]]; then
            echo "bucket=${{ env.S3_BUCKET_PROD }}" >> $GITHUB_OUTPUT
          elif [[ "$ENV" == "stg" ]]; then
            echo "bucket=${{ env.S3_BUCKET_STAGING }}" >> $GITHUB_OUTPUT
          else
            echo "bucket=${{ env.S3_BUCKET_DEV }}" >> $GITHUB_OUTPUT
          fi
      
      # Generate deployment timestamp for versioning
      - name: Generate timestamp
        id: set-timestamp
        run: |
          echo "timestamp=$(date +'%Y%m%d-%H%M%S')" >> $GITHUB_OUTPUT
      
      # Display deployment configuration for visibility
      - name: Display deployment config
        run: |
          echo "ðŸš€ Deployment Configuration:"
          echo "  Environment: ${{ steps.set-env.outputs.environment }}"
          echo "  S3 Bucket: ${{ steps.set-bucket.outputs.bucket }}"
          echo "  Timestamp: ${{ steps.set-timestamp.outputs.timestamp }}"
          echo "  Deploy CFN: ${{ github.event.inputs.deploy_cfn || 'true' }}"
          echo "  Deploy Lambdas: ${{ github.event.inputs.deploy_lambdas || 'true' }}"

  # Job 2: Deploy CloudFormation templates
  deploy-cfn-templates:
    name: Deploy CloudFormation Templates
    runs-on: ubuntu-latest
    needs: prepare-deployment
    # Only run if deploy_cfn is true (or not set, defaulting to true)
    if: github.event.inputs.deploy_cfn != 'false'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      # Configure AWS credentials using OIDC
      # This is more secure than storing long-lived credentials
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          # Role ARN stored as a repository/organization secret
          role-to-assume: ${{ secrets.AWS_DEPLOY_ROLE_ARN }}
          # Session name for CloudTrail audit logging
          role-session-name: GitHubActions-CFN-${{ github.run_id }}
          aws-region: ${{ env.AWS_REGION }}
          # How long the temporary credentials are valid (1 hour)
          role-duration-seconds: 3600
      
      # Install uv for fast Python package management
      - name: Install uv
        run: |
          # Install uv using the official installer
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH
      
      # Sync CloudFormation templates to S3
      - name: Sync CloudFormation templates to S3
        working-directory: .github/scripts
        env:
          S3_BUCKET: ${{ needs.prepare-deployment.outputs.s3_bucket }}
          S3_PREFIX: stacks/${{ needs.prepare-deployment.outputs.timestamp }}
          SOURCE_PATH: ../../CFN
          FILE_PATTERN: "*.yaml"
          SYNC_TYPE: files
          EXCLUDE_PATTERNS: ".git,__pycache__,*.pyc"
        run: |
          echo "ðŸ“¦ Syncing CloudFormation templates..."
          echo "  Source: $SOURCE_PATH"
          echo "  Destination: s3://$S3_BUCKET/$S3_PREFIX"
          
          # Run the sync script with uv (handles dependencies automatically)
          uv run s3_sync.py
          
          # Also create a 'latest' pointer for easy reference
          S3_PREFIX=stacks/latest uv run s3_sync.py

  # Job 3: Build and deploy Lambda functions
  deploy-lambda-functions:
    name: Deploy Lambda Functions
    runs-on: ubuntu-latest
    needs: prepare-deployment
    if: github.event.inputs.deploy_lambdas != 'false'
    
    # Matrix strategy to process multiple Lambda directories in parallel
    # This speeds up the deployment by running them concurrently
    strategy:
      matrix:
        lambda_type:
          - name: services
            path: Lambdas/Services
          - name: cleaners
            path: Lambdas/Cleaners
      # Continue processing other items even if one fails
      fail-fast: false
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_DEPLOY_ROLE_ARN }}
          role-session-name: GitHubActions-Lambda-${{ matrix.lambda_type.name }}-${{ github.run_id }}
          aws-region: ${{ env.AWS_REGION }}
          role-duration-seconds: 3600
      
      - name: Install uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH
      
      # Create ZIP files from Lambda directories and upload
      - name: Package and deploy Lambda functions
        working-directory: .github/scripts
        env:
          S3_BUCKET: ${{ needs.prepare-deployment.outputs.s3_bucket }}
          S3_PREFIX: lambdas/${{ matrix.lambda_type.name }}/${{ needs.prepare-deployment.outputs.timestamp }}
          SOURCE_PATH: ../../${{ matrix.lambda_type.path }}
          SYNC_TYPE: zip
          EXCLUDE_PATTERNS: "__pycache__,*.pyc,.git,.pytest_cache,tests"
        run: |
          echo "ðŸ“¦ Packaging Lambda functions from ${{ matrix.lambda_type.path }}..."
          echo "  Creating ZIPs and uploading to s3://$S3_BUCKET/$S3_PREFIX"
          
          # Create ZIPs and upload
          uv run s3_sync.py
          
          # Also update 'latest' for easy reference
          S3_PREFIX=lambdas/${{ matrix.lambda_type.name }}/latest uv run s3_sync.py

  # Job 4: Deploy Lambda Layer
  deploy-lambda-layer:
    name: Deploy Lambda Layer
    runs-on: ubuntu-latest
    needs: prepare-deployment
    if: github.event.inputs.deploy_lambdas != 'false'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_DEPLOY_ROLE_ARN }}
          role-session-name: GitHubActions-Layer-${{ github.run_id }}
          aws-region: ${{ env.AWS_REGION }}
          role-duration-seconds: 3600
      
      # Build Lambda layer with dependencies
      - name: Build Lambda layer
        run: |
          echo "ðŸ”¨ Building Lambda layer..."
          
          # Create directory structure for layer
          mkdir -p layer/python
          
          # Install dependencies from layer requirements
          if [ -f Lambdas/Services/Layer/requirements.txt ]; then
            pip install -r Lambdas/Services/Layer/requirements.txt -t layer/python/
          fi
          
          # Copy custom modules
          if [ -d Lambdas/Services/Layer/python ]; then
            cp -r Lambdas/Services/Layer/python/* layer/python/
          fi
          
          # Create ZIP file
          cd layer
          zip -r ../cyngular-layer.zip python/
          cd ..
          
          echo "âœ… Layer ZIP created: $(ls -lh cyngular-layer.zip | awk '{print $5}')"
      
      # Upload layer to S3
      - name: Upload layer to S3
        run: |
          TIMESTAMP="${{ needs.prepare-deployment.outputs.timestamp }}"
          BUCKET="${{ needs.prepare-deployment.outputs.s3_bucket }}"
          
          # Upload versioned
          aws s3 cp cyngular-layer.zip s3://$BUCKET/layers/$TIMESTAMP/cyngular-layer.zip
          
          # Upload as latest
          aws s3 cp cyngular-layer.zip s3://$BUCKET/layers/latest/cyngular-layer.zip
          
          echo "âœ… Layer uploaded to S3"

  # Job 5: Summary and notification
  deployment-summary:
    name: Deployment Summary
    runs-on: ubuntu-latest
    needs: 
      - prepare-deployment
      - deploy-cfn-templates
      - deploy-lambda-functions
      - deploy-lambda-layer
    # Always run this job, even if previous jobs failed
    if: always()
    
    steps:
      # Generate deployment summary
      - name: Generate summary
        run: |
          echo "# ðŸ“Š Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## ðŸŽ¯ Configuration" >> $GITHUB_STEP_SUMMARY
          echo "- **Environment**: ${{ needs.prepare-deployment.outputs.environment }}" >> $GITHUB_STEP_SUMMARY
          echo "- **S3 Bucket**: ${{ needs.prepare-deployment.outputs.s3_bucket }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Timestamp**: ${{ needs.prepare-deployment.outputs.timestamp }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## ðŸ“¦ Deployment Status" >> $GITHUB_STEP_SUMMARY
          echo "| Component | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|--------|" >> $GITHUB_STEP_SUMMARY
          
          # Check job statuses using needs context
          if [[ "${{ needs.deploy-cfn-templates.result }}" == "success" ]]; then
            echo "| CloudFormation Templates | âœ… Success |" >> $GITHUB_STEP_SUMMARY
          elif [[ "${{ needs.deploy-cfn-templates.result }}" == "skipped" ]]; then
            echo "| CloudFormation Templates | â­ï¸ Skipped |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| CloudFormation Templates | âŒ Failed |" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [[ "${{ needs.deploy-lambda-functions.result }}" == "success" ]]; then
            echo "| Lambda Functions | âœ… Success |" >> $GITHUB_STEP_SUMMARY
          elif [[ "${{ needs.deploy-lambda-functions.result }}" == "skipped" ]]; then
            echo "| Lambda Functions | â­ï¸ Skipped |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| Lambda Functions | âŒ Failed |" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [[ "${{ needs.deploy-lambda-layer.result }}" == "success" ]]; then
            echo "| Lambda Layer | âœ… Success |" >> $GITHUB_STEP_SUMMARY
          elif [[ "${{ needs.deploy-lambda-layer.result }}" == "skipped" ]]; then
            echo "| Lambda Layer | â­ï¸ Skipped |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| Lambda Layer | âŒ Failed |" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ðŸ”— Links" >> $GITHUB_STEP_SUMMARY
          echo "- [S3 Console](https://s3.console.aws.amazon.com/s3/buckets/${{ needs.prepare-deployment.outputs.s3_bucket }})" >> $GITHUB_STEP_SUMMARY
          echo "- [Workflow Run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY